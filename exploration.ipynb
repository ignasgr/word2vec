{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import cpu_count\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "\n",
    "from src.model import CBOW\n",
    "from src.collator import CBOWCollator\n",
    "from src.utils import preprocess, create_vocab\n",
    "from src.constants import (\n",
    "    EMBEDDING_DIMS,\n",
    "    VOCAB_SIZE,\n",
    "    MIN_WORD_FREQ,\n",
    "    CONTEXT_LENGTH,\n",
    "    SUBSAMPLE_THRESH,\n",
    ")\n",
    "from src.dataset import GenericPairDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CBOW(nn.Module):\n",
    "    def __init__(self, vocab_size, dims):\n",
    "        super().__init__()\n",
    "        self.embeddings = nn.Embedding(num_embeddings=vocab_size, embedding_dim=dims)\n",
    "        self.linear = nn.Linear(in_features=dims, out_features=vocab_size)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        embeds = self.embeddings(inputs).sum(dim=1)\n",
    "        out = self.linear(embeds)\n",
    "        return out\n",
    "    \n",
    "    def debug_forward(self, inputs):\n",
    "        embeds = self.embeddings(inputs)\n",
    "        print(embeds.shape)\n",
    "        print(embeds)\n",
    "        agg = embeds.sum(dim=1)\n",
    "        print(agg.shape)\n",
    "        print(agg)\n",
    "        out = self.linear(embeds)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_dataset(\n",
    "    \"deokhk/en_wiki_sentences_100000\", split=\"dev\", cache_dir=\"./data\"\n",
    ")\n",
    "data = data.map(preprocess, remove_columns=\"sentence\", num_proc=cpu_count() - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = create_vocab(\n",
    "    sentences=data[\"tokens\"], max_size=VOCAB_SIZE, min_freq=MIN_WORD_FREQ\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CBOW(vocab_size=len(vocabulary), dims=5)\n",
    "collator = CBOWCollator(context_length=CONTEXT_LENGTH, vocab=vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "contexts, targets = collator.collate(data[\"tokens\"])\n",
    "dataset = GenericPairDataset(contexts, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 8])\n",
      "tensor([[  4,   1,   0,   3, 252,  66,   0, 440],\n",
      "        [  0,   0,  10, 655,   6,   0,   0,   0]])\n",
      "torch.Size([2, 8, 5])\n",
      "tensor([[[ 4.2255e-02,  1.8558e+00,  1.0853e-01,  1.2185e+00, -6.7888e-01],\n",
      "         [ 1.2017e-01, -1.2318e+00, -9.4021e-01, -2.3804e-01,  8.5557e-01],\n",
      "         [ 5.6088e-01,  4.6863e-02,  7.0363e-01, -4.1738e-01, -1.0881e-01],\n",
      "         [ 1.1251e+00, -2.3331e+00,  1.1188e-01,  1.5523e+00,  8.0833e-01],\n",
      "         [-6.2213e-01, -8.3106e-01,  1.9010e+00,  1.0990e+00, -2.0834e+00],\n",
      "         [-6.1311e-02, -2.0460e-01,  1.0276e+00,  6.2708e-01, -5.1276e-01],\n",
      "         [ 5.6088e-01,  4.6863e-02,  7.0363e-01, -4.1738e-01, -1.0881e-01],\n",
      "         [-6.0386e-01,  5.9110e-01,  2.2420e-01, -2.0179e-01,  1.9633e+00]],\n",
      "\n",
      "        [[ 5.6088e-01,  4.6863e-02,  7.0363e-01, -4.1738e-01, -1.0881e-01],\n",
      "         [ 5.6088e-01,  4.6863e-02,  7.0363e-01, -4.1738e-01, -1.0881e-01],\n",
      "         [ 1.0571e+00,  9.1276e-01, -9.8245e-02,  2.1552e+00,  7.7171e-01],\n",
      "         [-4.9074e-01,  9.0866e-02, -5.4754e-04,  1.1254e+00, -3.0534e-01],\n",
      "         [ 8.7912e-01,  6.9838e-01, -7.7117e-01,  7.8913e-02, -8.2489e-01],\n",
      "         [ 5.6088e-01,  4.6863e-02,  7.0363e-01, -4.1738e-01, -1.0881e-01],\n",
      "         [ 5.6088e-01,  4.6863e-02,  7.0363e-01, -4.1738e-01, -1.0881e-01],\n",
      "         [ 5.6088e-01,  4.6863e-02,  7.0363e-01, -4.1738e-01, -1.0881e-01]]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n",
      "torch.Size([2, 5])\n",
      "tensor([[ 1.1220, -2.0600,  3.8402,  3.2222,  0.1345],\n",
      "        [ 4.2498,  1.9363,  2.6482,  1.2726, -0.9026]], grad_fn=<SumBackward1>)\n"
     ]
    }
   ],
   "source": [
    "for batch_contexts, batch_targets in dataloader:\n",
    "    print(batch_contexts.shape)\n",
    "    print(batch_contexts)\n",
    "    pred = model.debug_forward(batch_contexts)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.1220, -2.0600,  3.8402,  3.2222,  0.1345],\n",
       "        [ 4.2498,  1.9363,  2.6482,  1.2726, -0.9026]], grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.embeddings(batch_contexts).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.5954"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([-0.1966, 0.2234, -0.8973, -0.0871, 0.0592, -0.1966, -0.3767, 0.8763])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "word2vec",
   "language": "python",
   "name": "word2vec"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
